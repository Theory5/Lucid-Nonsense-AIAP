## this is the first attempt at creating a functioning logstash file in order to find and parse information within logs
## for elasticsearch
## This grok setup will not take into account elasticsearch analyzers for the time being
## The output and logs this script will eventually tackle will include
## tcpdump logs (from converted pcaps), apache2 logs, dionaea logs/output, kippo logs/output, bro logs, cuckoo logs and analyses, and misc.

## apache2... tested... works great!
input {
file {
type => "apache"
path => ["/var/log/apache2/access.log", "/var/log/apache2/error.log"]
}

## syslog... tested, works.
file {
    type => "syslog"
    path => [ "/var/log/*.log", "/var/log/messages", "/var/log/syslog" ]
  }
  
## lumberjack, now known as logstash forwarder... not tested

lumberjack {
port => 6782
ssl_certificate => "/etc/ssl/certs/irregsync.crt"
ssl_key => "/etc/ssl/certs/irregsync.key"
type => "lumberjack"

}


filter {
  grok {
    type  => "apache"
    match => [ "message" , "%{COMBINEDAPACHELOG}" ]
       }
  grok {
    type => "syslog"
    match => [ "message" , "%{SYSLOGBASE}" ]
       }
  date {
    match => [ "timestamp" , "dd/MMM/yyyy:HH:mm:ss Z" ]
  }
}

output {
elasticsearch {
host => localhost
}
stdout {
codec => rubydebug
}
}


