## this is the first attempt at creating a functioning logstash file in order to find and parse information within logs
## for elasticsearch
## This grok setup will not take into account elasticsearch analyzers for the time being
## The output and logs this script will eventually tackle will include
## tcpdump logs (from converted pcaps), apache2 logs, dionaea logs/output, kippo logs/output, bro logs, cuckoo logs and analyses, and misc.

## apache2... tested... works great!
input {
file {
type => "apache"
path => ["/var/log/apache2/access.log", "/var/log/apache2/error.log"]
}
## syslog... untested
file {
  type => "syslog"
  path => "var/log/syslog"
     }
}


filter {
  grok {
    type  => "apache"
    match => { "message" , "%{COMBINEDAPACHELOG}" }
       }
  grok {
    type => "syslog"
    match => { "message" , "%{SYSLOGLINE}" }
       }
  date {
    match => [ "timestamp" , "dd/MMM/yyyy:HH:mm:ss Z" ]
  }
}

output {
elasticsearch {
host => localhost
}
stdout {
codec => rubydebug
}
}


